{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Membuat data dummy\n",
    "np.random.seed(0)\n",
    "\n",
    "# Nama daerah\n",
    "daerah = ['Daerah_A', 'Daerah_B', 'Daerah_C', 'Daerah_D', 'Daerah_E']\n",
    "n_samples = 10000\n",
    "\n",
    "# Fitur geografis\n",
    "curah_hujan = np.random.uniform(50, 300, n_samples)  # Curah hujan dalam mm\n",
    "suhu = np.random.uniform(15, 35, n_samples)         # Suhu dalam derajat Celsius\n",
    "ketinggian = np.random.uniform(0, 2000, n_samples)  # Ketinggian dalam meter\n",
    "\n",
    "# Status potensi banjir (0: Aman, 1: Waspada, 2: Siaga, 3: Awas)\n",
    "status_banjir = np.random.randint(0, 4, n_samples)\n",
    "\n",
    "# Membuat DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Daerah': np.random.choice(daerah, n_samples),\n",
    "    'Curah Hujan': curah_hujan,\n",
    "    'Suhu': suhu,\n",
    "    'Ketinggian': ketinggian,\n",
    "    'Status Banjir': status_banjir\n",
    "})\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat data uji tanpa status potensi banjir\n",
    "n_test_samples = 100\n",
    "test_data = pd.DataFrame({\n",
    "    'Daerah': np.random.choice(daerah, n_test_samples),\n",
    "    'Curah Hujan': np.random.uniform(50, 300, n_test_samples),\n",
    "    'Suhu': np.random.uniform(15, 35, n_test_samples),\n",
    "    'Ketinggian': np.random.uniform(0, 2000, n_test_samples)\n",
    "})\n",
    "\n",
    "test_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Persiapan data untuk model\n",
    "X = data[['Curah Hujan', 'Suhu', 'Ketinggian']].values\n",
    "y = data['Status Banjir'].values\n",
    "\n",
    "# Standarisasi fitur\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Membagi data latih dan uji\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Implementasi Levenberg-Marquardt untuk model logistik\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def loss_function(params, X, y):\n",
    "    weights = params[:-1].reshape((X.shape[1], 1))\n",
    "    bias = params[-1]\n",
    "    predictions = sigmoid(X.dot(weights) + bias)\n",
    "    loss = -np.mean(y * np.log(predictions + 1e-8) + (1 - y) * np.log(1 - predictions + 1e-8))\n",
    "    return loss\n",
    "\n",
    "def gradient(params, X, y):\n",
    "    weights = params[:-1].reshape((X.shape[1], 1))\n",
    "    bias = params[-1]\n",
    "    predictions = sigmoid(X.dot(weights) + bias)\n",
    "    error = predictions - y.reshape(-1, 1)\n",
    "    grad_weights = X.T.dot(error) / X.shape[0]\n",
    "    grad_bias = np.sum(error) / X.shape[0]\n",
    "    return np.concatenate([grad_weights.ravel(), [grad_bias]])\n",
    "\n",
    "def levenberg_marquardt(X, y, initial_params, num_iterations=100):\n",
    "    params = initial_params\n",
    "    mu = 0.01\n",
    "    lambda_factor = 10\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        grad = gradient(params, X, y)\n",
    "        loss = loss_function(params, X, y)\n",
    "        \n",
    "        # Update step\n",
    "        params -= mu * grad\n",
    "        \n",
    "        # Check if loss decreases\n",
    "        new_loss = loss_function(params, X, y)\n",
    "        if new_loss < loss:\n",
    "            mu /= lambda_factor\n",
    "        else:\n",
    "            mu *= lambda_factor\n",
    "    \n",
    "    return params\n",
    "\n",
    "# Inisialisasi parameter\n",
    "initial_params = np.random.randn(X_train.shape[1] + 1)\n",
    "\n",
    "# Menjalankan LM\n",
    "optimized_params = levenberg_marquardt(X_train, y_train, initial_params)\n",
    "print(\"Optimized Parameters:\", optimized_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping kategori\n",
    "status_mapping = {0: 'Aman', 1: 'Waspada', 2: 'Siaga', 3: 'Awas'}\n",
    "\n",
    "# Fungsi untuk memetakan hasil prediksi ke kategori\n",
    "def map_predictions(predictions):\n",
    "    return [status_mapping[int(pred)] for pred in predictions]\n",
    "\n",
    "# Prediksi pada data uji\n",
    "predictions = predict(X_test_scaled, optimized_params)\n",
    "predicted_statuses = map_predictions(predictions)\n",
    "\n",
    "# Menampilkan hasil\n",
    "test_data['Predicted Status'] = predicted_statuses\n",
    "print(test_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
